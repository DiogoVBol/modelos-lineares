---
title: "Atividade 6 - Modelos Lineares"
output: html_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```

### Alunos: Davi Augusto, Diogo Bolzan, João Arend, Luan Frederico e Thiago Schedler.


## Questão 1

![=](img/01.jpeg)
![=](img/02.jpeg)

## Questão 2

![=](img/03.jpeg)

## Questão 3

### a) Estime e interprete os coeficientes do modelo de regressao.

```{r}
n <- 10
soma_y <- 20
soma_x1 <- 30
soma_x2 <- 40
soma_y2 <- 88.2
soma_x1_squared <- 92
soma_x2_squared <- 163
soma_yx1 <- 59
soma_yx2 <- 88
soma_x1x2 <- 119

# Matriz X'X
XTX <- matrix(c(
  n, soma_x1, soma_x2,
  soma_x1, soma_x1_squared, soma_x1x2,
  soma_x2, soma_x1x2, soma_x2_squared
), nrow = 3, byrow = TRUE)

# Vetor X'Y
XTY <- c(soma_y, soma_yx1, soma_yx2)

beta <- solve(XTX) %*% XTY
beta
# Beta_{0} = -13
# Beta_{1} = 1
# Beta_{2} = 3
```
Interpretação:

**Intercepto ($B_{0})$**: Representa o valor esperado de $Y$ (-13) quando $X_{1}$ e $X_{2}$ é zero.

**Coeficiente de $X_{1}$ ($B_{1}$)**: Indica a variação em $Y$ para cada unidade de aumento em $X_{1}$, mantendo $X_{2}$ constante.

**Intercepto ($B_{0})$**: Representa o valor esperado de $Y$ (-13) quando $X_{1}$ e $X_{2}$ é zero.

**Coeficiente de $X_{2}$ ($B_{2}$)**: Indica a variação em $Y$ para cada unidade de aumento em $X_{2}$, mantendo $X_{1}$ constante.

### b) Calcule e interprete o coeficiente de determinação ajustado

$$
R_{ajustado}^{2}=1-\frac{(1-R^{2})(n-1)}{n-k-1}
$$
Onde:

- $R^{2}$: Coeficiente de determinação comum.

- $n$: Número de observações.

- $k$: Número de variáveis independentes.

````{r}
media_y <- soma_y / n
X <- matrix(c(rep(1, n), soma_x1 / n, soma_x2 / n), ncol = 3, byrow = TRUE)
Y_hat <- X %*% beta
# Calcular o R primeiro

## Soma de quadrados total
SQtotal <- soma_y2 - n * (media_y^2)

## Soma de quadrados dos resíduos
SQres <- soma_y2 - sum(Y_hat^2)

## Soma de quadrados da regressão
SQreg <- SQtotal - SQres

# Coeficiente de determinação (R^2)
R2 <- SQreg / SQtotal

# Coeficiente de determinação ajustado (R^2 ajustado)
R2_ajustado <- 1 - ((1 - R2) * (n - 1) / (n - 3))

R2_ajustado
````
Interpretação:

- $R^{2}:$ Mede a proporçaõ de variação total de $Y$ explicada pelas variáveis $X_{1}$ e $X_{2}$.
- $R_{ajustado}^{2}:$ Ajuda o $R^{2}$ para o número de variáveis independentes do modelo, penalizando a inclusão de variáveis irrelevantes.

### c) Calcule e interprete o intervalode 95% de confoança para o coeficiente angular de X1.

````{R}
# Soma de quadrados dos resíduos
SQres <- soma_y2 - t(beta) %*% XTY

sigma2 <- as.numeric(SQres / (n - 3))

# Erro padrão do coeficiente de X1
SE_beta1 <- sqrt(sigma2 * solve(XTX)[2, 2])

t_critico <- qt(0.975, df = n - 3)

# Intervalo de confiança para o coeficiente de X1
beta1 <- beta[2]
IC_beta1 <- c(
  beta1 - t_critico * SE_beta1,
  beta1 + t_critico * SE_beta1
)

IC_beta1
````
O intervalo de confiança para o coeficiente $X_{1}$ é de [-2.47,4.47] e indica o intervalo dentro do qual o real coeficiente está presente com 95% de certeza.
O intervalo contém o zero, e portanto o coeficiente não é estatisticamente significativo, inficando que $X_{1}$ não tem um efeito relevante sobre o $Y$.

### d) Teste a hipotese de que X2 exerce influencia linear sobre Y, a 5% de nível de significancia.

````{r}
sigma2 <- as.numeric(SQres / (n - 3))

# Erro padrão do coeficiente de X2
SE_beta2 <- sqrt(sigma2 * solve(XTX)[3, 3])

# Estatística t para X2
beta2 <- beta[3]
t_stat <- beta2 / SE_beta2

# Valor crítico de t para 95% de confiança (nível de significância 5%)
t_critico <- qt(0.975, df = n - 3)

p_valor <- 2 * (1 - pt(abs(t_stat), df = n - 3))

list(
  Estatistica_t = t_stat,
  Valor_critico = t_critico,
  p_valor = p_valor
)

````
Interpretação:

Como o valor de p é menor que 0.05, há evidencias para concluir que podemos rejeitar $H_{0}$ indicando que $X_{2}$ tem influência linear significativa.

### e) Teste a significancia global da regressao, a 5% de nível de significancia. Especifique as hipóteses e interprete.

````{R}
k <- 2
df_reg <- 2
df_res <- n - 3

# Estatística F
F_stat <- (SQreg / df_reg) / (SQres / df_res)

# Valor crítico de F
F_critico <- qf(0.95, df1 = df_reg, df2 = df_res)

p_valor <- 1 - pf(F_stat, df1 = df_reg, df2 = df_res)

list(
  Estatistica_F = F_stat,
  Valor_critico = F_critico,
  p_valor = p_valor
)

````

Interpretação:

Como o valor de p é menor que 0.05, há evidencias para rejeitar $H_{0}$, indicando que o modelo é significativo.

## Questão 4
Dada a amostra abaixo, calcule.
Y X1 X2
5 1 1
6 2 1
7 3 2
8 4 2
8 5 2
```{r, include=FALSE}

y  = c(5, 6, 7, 8, 8)
x1 = c(1, 2, 3, 4, 5)
x2 = c(1, 1, 2, 2, 2)

dados <- data.frame(
  Y  = y,
  X1 = x1,
  X2 = x2)
```
### a: Construa um intervalo de 90% de confiança para os parâmetros do modelo.
```{r 4a}

modelo <- lm(Y ~ X1 + X2, data = dados)

cat("Intervalo de confiança de 90% para os parâmetros:\n")
confint(modelo, level = 0.90)
```
### b: Qual a equação de regressão estimada?
```{r 4b}

coeficientes <- coef(modelo)

cat("Equação de regressão estimada:\n")
cat(sprintf("Y = %.2f + %.2f*X1 + %.2f*X2\n", coeficientes[1], coeficientes[2], coeficientes[3]))
```
### c: Construa a tabela ANOVA, qual a sua conclusão?
```{r 4c}

cat("Tabela anova:\n")
anova(modelo)
```
### d: Calcule e interprete os coeficientes de determinação parciais de Y X1.X2 e Y X2.X21
```{r 4d}
library(ppcor)
ry1_2 = pcor.test(y, x1, x2)
ry1_2
(ry1_2$estimate)^2

ry2_1 = pcor.test(y, x2, x1)
ry2_1

(ry2_1$estimate)^2
```
Portanto `r (ry1_2$estimate)^2 * 100`% da variabilidade de Y é explicada por X1 mantendo X2 constante e `r (ry2_1$estimate)^2 * 100`% da variabilidade de Y é explicada por X2 mantendo X1 constante.
**obs:** Os valores estimados para coeficiente de correlação parcial não foram significativos.

## Questão 5

# Esboce graficamente o modelo estimado
```{r}
library(gridExtra)
library(ggplot2)

# Configuração do modelo
beta0 <- 1000
beta1 <- 500
alpha1 <- 0.9

X <- seq(0, 20, by = 0.01)

# Calcular Y para Z = 0 e Z = 1
Y_Z0 <- beta0 + beta1 * X + (alpha1 * 0)
Y_Z1 <- beta0 + beta1 * X + (alpha1 * 1)


# Criar o gráfico
z0 = ggplot()+
  geom_line(aes(X,Y_Z0),color = "blue") +
  labs( x = "Tempo de serviço",
        y = "Salário",
        title =  "Para Z = 0") +
  theme_minimal()



z1 = ggplot()+
  geom_line(aes(X,Y_Z1),color = "red") +
  labs( x = "Tempo de serviço",
        y = "Salário",
        title =  "Para Z = 1") +
  theme_minimal()

grid.arrange(z0,z1,nrow=1,ncol= 2)
```


# Interprete o valor do coeficiente da variável Z

  Espera-se que indivíduos com nível superior tenham, em média, um salário 0.9 unidades monetárias maior em comparação com aqueles sem nível superior. Embora positivo, o impacto da escolaridade no salário é relativamente pequeno em relação ao efeito do tempo de serviço, não sendo possível visualizar essa diferença nos gráficos acima.
  
  
# Teste, a 5% de significância, se existe influência do nível educacional no salário.

```{r}
beta_Z <- 0.9
se_beta_Z <- 0.1
n <- 20

t_stat <- beta_Z / se_beta_Z

df <- n - 2

t_crit <- qt(0.975, df)

p_value <- 2 * (1 - pt(abs(t_stat), df))

cat("Valor-p:", p_value, "\n")

```

  Como o p-valor foi significativo, há evidências de que o nível educacional (variável Z) influencia o salário. No entanto, é importante observar que a magnitude dessa influência é pequena, com uma diferença salarial de apenas 0.9 unidades monetárias entre indivíduos com e sem nível superior. Isso sugere que, embora o nível educacional tenha um efeito estatisticamente significativo no salário, esse impacto é relativamente modesto em comparação com outras variáveis, como o tempo de serviço.

## Questão 6

Considere o seguinte modelo estimado para explicar salários via nível educacional e experiência
profissional:

$$
\widehat{\log(\text{salários})} = 7,42 + 0,29 \cdot \text{grad} + 0,04 \cdot \text{exper}
$$

em que:

- \(\text{grad} = 1\) se possui curso superior, e \(0\) caso contrário;
- \(\text{exper}\) são os anos de experiência profissional.

Além disso, os valores de ajuste do modelo são:

- \(R^2 = 0,2731\),
- \(R^2_{\text{ajustado}} = 0,152\),
- \(n = 15\).

### a) Interprete os coecientes estimados neste modelo.

**Interpretação de $\beta_0$**: O intercepto (\(\beta_0\)) é o coeficiente \(7,42\), que representa o valor esperado do logaritmo do salário (\(\log(\text{salários})\)) para indivíduos sem curso superior (\(\text{grad} = 0\)) e sem experiência profissional (\(\text{exper} = 0\)), que ocorre quando as variáveis **grad** e **exper** são iguais a zero. 
Como o modelo está em escala de logaritmos, \(\beta_0\) não representa diretamente o salário, mas sim o logaritmo do salário. Para interpretar em termos de salário, é necessário calcular \(e^{\beta_0}\), que forneceria o salário esperado.  

**Interpretação de $\beta_1$**: O coeficiente \(0,29\) significa que, mantendo-se constante a experiência profissional (\(\text{exper}\)),
ter curso superior (\(\text{grad} = 1\)) está associado a um aumento médio de \(29\%\) no salário em relação a não ter curso superior (\(\text{grad} = 0\)).

Essa interpretação decorre da propriedade exponencial dos logaritmos:

\[
\Delta \log(\text{salários}) = 0,29 \implies \Delta \text{salários} \approx e^{0,29} - 1 \approx 0,29 \, \text{(ou 29\%)}.
\]

**Interpretação de $\beta_2$**: O coeficiente \(0,04\) significa que, mantendo-se constante o nível educacional (\(\text{grad}\)), cada ano adicional
de experiência profissional está associado a um aumento médio de \(4\%\) no salário.

Assim como no caso anterior, isso pode ser interpretado usando a relação exponencial:

\[
\Delta \log(\text{salários}) = 0,04 \implies \Delta \text{salários} \approx e^{0,04} - 1 \approx 0,04 \, \text{(ou 4\%)}.
\]  

### b) Esboce o gráfico de log do salário em função da experiência profissional para pessoas com graduação e sem graduação.

```{r}
# Criando os dados
exper = seq(0, 40, by = 1) # de 0 a 40 anos de experiência
log_salario_sem_grad = 7.42 + 0.04 * exper
log_salario_com_grad = 7.42 + 0.29 + 0.04 * exper

# Criando um data frame para o ggplot
dados = data.frame(
  Experiencia = rep(exper, 2),
  LogSalario = c(log_salario_sem_grad, log_salario_com_grad),
  Graduacao = rep(c("Sem Graduação", "Com Graduação"), each = length(exper))
)

# Gerando o gráfico
ggplot(dados, aes(x = Experiencia, y = LogSalario, color = Graduacao)) +
  geom_line(size = 1.2) +
  labs(
    title = "Log do salário em função da experiência profissional",
    x = "Experiência Profissional (anos)",
    y = expression(log(salários)),
    color = "Graduação"
  ) +
  theme_minimal() +
  scale_color_manual(values = c("blue", "red"))
```

### c) Proponha um modelo que considere diferentes inclinações na reta de regressão para graduados e não graduados.

\[
\text{log(salário)} = \beta_0 + \beta_1 \cdot \text{exper} + \beta_2 \cdot \text{grad} + \beta_3 \cdot (\text{exper} \cdot \text{grad})
\]

Para encontar o modelo acima, não há algum cálculo específico para encontrá-la, mas sim uma fundamentação baseada em teorias estatísticas.  

Com base neste modelo, podemos encontrar os modelos para as pessoas com graduação e sem graduação, segue que:

Para não graduados (\( \text{grad} = 0 \)): Substituímos \( \text{grad} = 0 \) na equação,o modelo fica assim:
\[
\text{log(salário)} = \beta_0 + \beta_1 \cdot \text{exper}
\]

Aqui, a inclinação em relação à experiência é apenas \( \beta_1 \).  

Para graduados (\( \text{grad} = 1 \)): Substituímos \( \text{grad} = 1 \) na equação:
\[
\text{log(salário)} = \beta_0 + \beta_1 \cdot \text{exper} + \beta_2 + \beta_3 \cdot \text{exper}
\]

Aqui, a inclinação em relação à experiência é \( \beta_1 + \beta_3 \).

Em que O termo $\beta_3$ representa a diferença na inclinação da relação entre experiência e log do salário entre graduados e não graduados.  

### d) Qual seria a hipótese nula para testar se há diferença nas inclinações entre graduados e não graduados no modelo do item anterior? 

A hipótese nula para testar se há diferença nas inclinações entre graduados e não graduados no modelo do item anterior, que inclui o termo de interação,
seria testar se o coeficiente de interação ($\beta_3$) é igual a zero. Assim, as hipóteses seriam:
$$ H_0: \beta_3 = 0 \quad vs \quad H_1: \beta_3 \neq 0$$  

- Se $\beta_3 = 0$, isso indica que não há diferença na inclinação entre graduados e não graduados.
Ou seja, a relação entre experiência e salário seria a mesma para os dois grupos.

- Se $\beta_3 \neq 0$, isso indica que há uma diferença significativa nas inclinações entre os dois grupos.
Ou seja, a relação entre experiência e salário difere para graduados e não graduados.

Esta hipótese pode ser calculada através de um teste t para o coeficiente $\beta_3$ no modelo ajustado.

